{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model for Whatsapp's Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "import string\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeVocabulary():\n",
    "    unkToken = '<UNK>'\n",
    "    #create another vocab inside vocab -> text to index\n",
    "    vocab['t_2_i'] = {}\n",
    "    #create another vocab inside vocab -> index to text\n",
    "    vocab['i_2_t'] = {}\n",
    "    # Add token in key 'unkToken' = '<UNK>'\n",
    "    vocab['unkToken'] = unkToken\n",
    "    # call function 'addToken()' that return token index\n",
    "    idx = addToken(unkToken)\n",
    "    vocab['unkTokenIdx'] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addToken(token):\n",
    "    # if token already in vocab then just return index\n",
    "    if token in vocab['t_2_i']:\n",
    "        idx = vocab['t_2_i'][token]\n",
    "    else:\n",
    "        # create index for new tokken --> simply new index == len(vocab) /*last number*/\n",
    "        idx = len(vocab['t_2_i'])\n",
    "        vocab['t_2_i'][token] = idx\n",
    "        vocab['i_2_t'][idx] = token\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addManyTokens(tokens):\n",
    "    idxes = [addToken(token) for token in tokens]\n",
    "    return idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookUpToken(token):\n",
    "    return vocab['t_2_i'].get(token,vocab['unkTokenIdx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookUpIndex(idx):\n",
    "    if idx not in vocab['i_2_t']:\n",
    "        raise KeyError(\"the index (%d) is not there\" % idx)\n",
    "    return vocab['i_2_t'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabularyFromDataFrame(df,cutoff=5):\n",
    "    initializeVocabulary()\n",
    "    wordCounts = Counter()\n",
    "    for r in df.Message:\n",
    "        for word in re.split('\\W+',r):\n",
    "            wordCounts[word] += 1\n",
    "    for word,count in wordCounts.items():\n",
    "        if count > cutoff:\n",
    "            addToken(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabularyFromCorpus(Corpus,cutoff=2):\n",
    "    initializeVocabulary()\n",
    "    wordCounts = Counter()\n",
    "    for doc in Corpus:\n",
    "        for word in re.split('\\W+',doc):\n",
    "            wordCounts[word] += 1\n",
    "    for word,count in wordCounts.items():\n",
    "        if count > cutoff:\n",
    "            addToken(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotVector(token,N):\n",
    "    oneHot = np.zeros((N,1))\n",
    "    oneHot[lookUpToken(token)] = 1\n",
    "    return oneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Whatsapp_chat_Data.xlsx')\n",
    "# Drop NaN values in Dataframe\n",
    "df = df.dropna()\n",
    "# Change Column value --> from 'fear' to 'Fear' :)\n",
    "#df[\"Mode\"].replace({\"Angry \": \"Angry\", \"fear\": \"Fear\",}, inplace=True)\n",
    "\n",
    "# Change Column value --> from 'fear' to 'Fear' :)\n",
    "df[\"Mode\"].replace({\"Normal\": \"Positive\", \"Happy\": \"Positive\", \"Love\": \"Positive\",}, inplace=True)\n",
    "df[\"Mode\"].replace({\"Angry\": \"Negative\", \"Fear\": \"Negative\", \"Sad\": \"Negative\",}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Positive'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the unique values of 'Mode' column\n",
    "df.Mode.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    1124\n",
       "Negative     793\n",
       "Name: Mode, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Mode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a simple line plot\n",
    "#df.plot(kind='bar',x='Mode',y='Message')\n",
    "df.groupby('Mode')['Message'].nunique().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mode</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Hmme na pagal ho chuki har teacher ki mintaien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Or phir teachers k krny waly kam b me he kron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Allah kry maan jay ab bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Abhe aca ki assignments rehti hain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Ab Eid tu guzarny dein sakoon se</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Mode                                            Message\n",
       "0  Negative  Hmme na pagal ho chuki har teacher ki mintaien...\n",
       "1  Negative      Or phir teachers k krny waly kam b me he kron\n",
       "2  Negative                          Allah kry maan jay ab bus\n",
       "3  Negative                 Abhe aca ki assignments rehti hain\n",
       "5  Negative                   Ab Eid tu guzarny dein sakoon se"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabularyFromDataFrame(df, cutoff=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "837"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab['t_2_i'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uss'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookUpIndex(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(message):\n",
    "    isFirst = True\n",
    "    for token in message.split(\" \"):\n",
    "        if token not in string.punctuation:\n",
    "            oneHot = np.zeros((len(vocab['t_2_i']),1))\n",
    "            oneHot[lookUpToken(token)] = 1\n",
    "            if isFirst:\n",
    "                xF = oneHot\n",
    "                isFirst = False\n",
    "            else:\n",
    "                xF = np.hstack((xF,oneHot))\n",
    "    return xF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "xF = vectorize(df['Message'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We just use oneHOt emedding ... \n",
    "##for better choice you may choice word to vector emedding and so on ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(837, 11)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xF.shape\n",
    "#df['Message'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallDf_pos = df[df['Mode']=='Positive'].iloc[:5]\n",
    "smallDf_neg = df[df['Mode']=='Negative'].iloc[:5]\n",
    "df_small = pd.concat([smallDf_pos,smallDf_neg], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocabularyFromDataFrame(df_small, cutoff=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mode</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Ya puchna ya tha k Shair kisi b traha ka send ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Han g phir to any dain gy per ap k any k bgair...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Everyone please bs kro yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Positive</td>\n",
       "      <td>Itny ap sary Fawad khan rehty ni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Positive</td>\n",
       "      <td>ok then MOV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Tu to chup kr ja desh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Bush kr de bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Tra GB delete ni howa kia abho tak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Negative</td>\n",
       "      <td>Gustakhi ki mafi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Negative</td>\n",
       "      <td>tum tu barhana chahty thy teli lga k gaib hat ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Mode                                            Message\n",
       "2   Positive  Ya puchna ya tha k Shair kisi b traha ka send ...\n",
       "3   Positive  Han g phir to any dain gy per ap k any k bgair...\n",
       "4   Positive                          Everyone please bs kro yr\n",
       "6   Positive                   Itny ap sary Fawad khan rehty ni\n",
       "8   Positive                                        ok then MOV\n",
       "0   Negative                              Tu to chup kr ja desh\n",
       "1   Negative                                    Bush kr de bush\n",
       "5   Negative                 Tra GB delete ni howa kia abho tak\n",
       "10  Negative                                   Gustakhi ki mafi\n",
       "15  Negative  tum tu barhana chahty thy teli lga k gaib hat ..."
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "numFeatures = len(vocab['t_2_i'])\n",
    "hiddenUnits = 10\n",
    "h0 = torch.tensor(np.zeros((hiddenUnits,1)))\n",
    "Wx = torch.tensor(np.random.uniform(0,1,(hiddenUnits,numFeatures)),requires_grad=True)\n",
    "Wh = torch.tensor(np.random.uniform(0,1,(hiddenUnits,hiddenUnits)),requires_grad=True)\n",
    "Wy = torch.tensor(np.random.uniform(0,1,(1,hiddenUnits)),requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10]) torch.Size([10, 837]) torch.Size([1, 10]) torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "print(Wh.shape,Wx.shape,Wy.shape,h0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepForward(xt,Wx,Wh,Wy,prevMemory):\n",
    "    #x_frd = torch.matmul(Wx,torch.from_numpy(xt))\n",
    "    #print(\"1: \",Wx.shape,torch.from_numpy(xt[:,np.newaxis]).shape)\n",
    "    x_frd = torch.matmul(Wx,torch.from_numpy(xt[:,np.newaxis]))\n",
    "    #print(\"2: \",Wh.shape,prevMemory.shape)\n",
    "    h_frd = torch.matmul(Wh,prevMemory)\n",
    "    ht = torch.tanh(x_frd+h_frd)\n",
    "    yt_hat = torch.sigmoid(torch.matmul(Wy,ht))\n",
    "    #yt_hat = F.softmax(torch.matmul(Wy,ht),dim=0)\n",
    "    return ht,yt_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullForwardRNN(X,Wx,Wh,Wy,prevMemory):\n",
    "    y_hat = []\n",
    "    for t in range(X.shape[1]):\n",
    "        ht,yt_hat = stepForward(X[:,t],Wx,Wh,Wy,prevMemory)\n",
    "        prevMemory = ht\n",
    "        y_hat = yt_hat\n",
    "        #y_hat.append(yt_hat)\n",
    "    return y_hat  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeLoss(y,y_hat):\n",
    "    loss = 0\n",
    "    for yi,yi_hat in zip(y,y_hat):\n",
    "        if yi == 1:\n",
    "            loss += -torch.log2(yi_hat)\n",
    "        else:\n",
    "            loss += -torch.log2(1-yi_hat)\n",
    "        #Li = -torch.log2(yi_hat[yi==1])\n",
    "        #loss += Li\n",
    "    return loss/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateParams(Wx,Wh,Wy,dWx,dWh,dWy,lr):\n",
    "    with torch.no_grad():\n",
    "        Wx -= lr*dWx\n",
    "        Wh -= lr*dWh\n",
    "        Wy -= lr*dWy\n",
    "    return Wx,Wh,Wy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainRNN(train_df,Wx,Wh,Wy,prevMemory,lr,nepoch):\n",
    "    losses = []\n",
    "    for epoch in range(nepoch):\n",
    "        y,y_hat = [],[]\n",
    "        for msg,mod in zip(train_df['Message'],train_df['Mode']):\n",
    "            X = vectorize(msg)\n",
    "            #print('``````````````~~~~~~~~~~~~~~~~~~`````````````````')\n",
    "            #print(X.shape)\n",
    "            yi_hat = fullForwardRNN(X,Wx,Wh,Wy,prevMemory)\n",
    "            yi = 0\n",
    "            if mod == 'Positive':\n",
    "                yi = 1\n",
    "            y.append(yi)\n",
    "            y_hat.append(yi_hat)\n",
    "                \n",
    "        loss = computeLoss(y,y_hat)\n",
    "        loss.backward()\n",
    "        losses.append(loss)\n",
    "        print(\"Loss after epoch=%d: %f\" %(epoch,loss))\n",
    "        sys.stdout.flush()\n",
    "        dWx = Wx.grad.data\n",
    "        dWh = Wh.grad.data\n",
    "        dWy = Wy.grad.data\n",
    "        Wx,Wh,Wy = updateParams(Wx,Wh,Wy,dWx,dWh,dWy,lr)\n",
    "        Wx.grad.data.zero_()\n",
    "        Wh.grad.data.zero_()\n",
    "        Wy.grad.data.zero_()\n",
    "    return Wx,Wh,Wy,losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch=0: 2.957864\n",
      "Loss after epoch=1: 2.954424\n",
      "Loss after epoch=2: 2.950985\n",
      "Loss after epoch=3: 2.947547\n",
      "Loss after epoch=4: 2.944110\n",
      "Loss after epoch=5: 2.940673\n",
      "Loss after epoch=6: 2.937238\n",
      "Loss after epoch=7: 2.933802\n",
      "Loss after epoch=8: 2.930368\n",
      "Loss after epoch=9: 2.926934\n",
      "Loss after epoch=10: 2.923501\n",
      "Loss after epoch=11: 2.920069\n",
      "Loss after epoch=12: 2.916638\n",
      "Loss after epoch=13: 2.913207\n",
      "Loss after epoch=14: 2.909777\n",
      "Loss after epoch=15: 2.906348\n",
      "Loss after epoch=16: 2.902919\n",
      "Loss after epoch=17: 2.899492\n",
      "Loss after epoch=18: 2.896065\n",
      "Loss after epoch=19: 2.892639\n",
      "Loss after epoch=20: 2.889213\n",
      "Loss after epoch=21: 2.885789\n",
      "Loss after epoch=22: 2.882365\n",
      "Loss after epoch=23: 2.878942\n",
      "Loss after epoch=24: 2.875520\n",
      "Loss after epoch=25: 2.872098\n",
      "Loss after epoch=26: 2.868678\n",
      "Loss after epoch=27: 2.865258\n",
      "Loss after epoch=28: 2.861839\n",
      "Loss after epoch=29: 2.858421\n",
      "Loss after epoch=30: 2.855003\n",
      "Loss after epoch=31: 2.851587\n",
      "Loss after epoch=32: 2.848171\n",
      "Loss after epoch=33: 2.844756\n",
      "Loss after epoch=34: 2.841342\n",
      "Loss after epoch=35: 2.837929\n",
      "Loss after epoch=36: 2.834517\n",
      "Loss after epoch=37: 2.831105\n",
      "Loss after epoch=38: 2.827695\n",
      "Loss after epoch=39: 2.824285\n",
      "Loss after epoch=40: 2.820876\n",
      "Loss after epoch=41: 2.817468\n",
      "Loss after epoch=42: 2.814061\n",
      "Loss after epoch=43: 2.810655\n",
      "Loss after epoch=44: 2.807249\n",
      "Loss after epoch=45: 2.803845\n",
      "Loss after epoch=46: 2.800441\n",
      "Loss after epoch=47: 2.797038\n",
      "Loss after epoch=48: 2.793637\n",
      "Loss after epoch=49: 2.790236\n",
      "Loss after epoch=50: 2.786836\n",
      "Loss after epoch=51: 2.783437\n",
      "Loss after epoch=52: 2.780039\n",
      "Loss after epoch=53: 2.776642\n",
      "Loss after epoch=54: 2.773245\n",
      "Loss after epoch=55: 2.769850\n",
      "Loss after epoch=56: 2.766456\n",
      "Loss after epoch=57: 2.763062\n",
      "Loss after epoch=58: 2.759670\n",
      "Loss after epoch=59: 2.756279\n",
      "Loss after epoch=60: 2.752888\n",
      "Loss after epoch=61: 2.749499\n",
      "Loss after epoch=62: 2.746110\n",
      "Loss after epoch=63: 2.742722\n",
      "Loss after epoch=64: 2.739336\n",
      "Loss after epoch=65: 2.735950\n",
      "Loss after epoch=66: 2.732566\n",
      "Loss after epoch=67: 2.729182\n",
      "Loss after epoch=68: 2.725800\n",
      "Loss after epoch=69: 2.722418\n",
      "Loss after epoch=70: 2.719038\n",
      "Loss after epoch=71: 2.715658\n",
      "Loss after epoch=72: 2.712280\n",
      "Loss after epoch=73: 2.708902\n",
      "Loss after epoch=74: 2.705526\n",
      "Loss after epoch=75: 2.702151\n",
      "Loss after epoch=76: 2.698776\n",
      "Loss after epoch=77: 2.695403\n",
      "Loss after epoch=78: 2.692031\n",
      "Loss after epoch=79: 2.688660\n",
      "Loss after epoch=80: 2.685290\n",
      "Loss after epoch=81: 2.681921\n",
      "Loss after epoch=82: 2.678553\n",
      "Loss after epoch=83: 2.675187\n",
      "Loss after epoch=84: 2.671821\n",
      "Loss after epoch=85: 2.668456\n",
      "Loss after epoch=86: 2.665093\n",
      "Loss after epoch=87: 2.661731\n",
      "Loss after epoch=88: 2.658370\n",
      "Loss after epoch=89: 2.655010\n",
      "Loss after epoch=90: 2.651651\n",
      "Loss after epoch=91: 2.648293\n",
      "Loss after epoch=92: 2.644936\n",
      "Loss after epoch=93: 2.641581\n",
      "Loss after epoch=94: 2.638227\n",
      "Loss after epoch=95: 2.634874\n",
      "Loss after epoch=96: 2.631522\n",
      "Loss after epoch=97: 2.628171\n",
      "Loss after epoch=98: 2.624821\n",
      "Loss after epoch=99: 2.621473\n",
      "Loss after epoch=100: 2.618126\n",
      "Loss after epoch=101: 2.614780\n",
      "Loss after epoch=102: 2.611435\n",
      "Loss after epoch=103: 2.608092\n",
      "Loss after epoch=104: 2.604749\n",
      "Loss after epoch=105: 2.601408\n",
      "Loss after epoch=106: 2.598068\n",
      "Loss after epoch=107: 2.594730\n",
      "Loss after epoch=108: 2.591392\n",
      "Loss after epoch=109: 2.588056\n",
      "Loss after epoch=110: 2.584721\n",
      "Loss after epoch=111: 2.581388\n",
      "Loss after epoch=112: 2.578056\n",
      "Loss after epoch=113: 2.574725\n",
      "Loss after epoch=114: 2.571395\n",
      "Loss after epoch=115: 2.568067\n",
      "Loss after epoch=116: 2.564739\n",
      "Loss after epoch=117: 2.561414\n",
      "Loss after epoch=118: 2.558089\n",
      "Loss after epoch=119: 2.554766\n",
      "Loss after epoch=120: 2.551444\n",
      "Loss after epoch=121: 2.548124\n",
      "Loss after epoch=122: 2.544805\n",
      "Loss after epoch=123: 2.541487\n",
      "Loss after epoch=124: 2.538170\n",
      "Loss after epoch=125: 2.534855\n",
      "Loss after epoch=126: 2.531542\n",
      "Loss after epoch=127: 2.528229\n",
      "Loss after epoch=128: 2.524919\n",
      "Loss after epoch=129: 2.521609\n",
      "Loss after epoch=130: 2.518301\n",
      "Loss after epoch=131: 2.514994\n",
      "Loss after epoch=132: 2.511689\n",
      "Loss after epoch=133: 2.508385\n",
      "Loss after epoch=134: 2.505083\n",
      "Loss after epoch=135: 2.501782\n",
      "Loss after epoch=136: 2.498482\n",
      "Loss after epoch=137: 2.495184\n",
      "Loss after epoch=138: 2.491887\n",
      "Loss after epoch=139: 2.488592\n",
      "Loss after epoch=140: 2.485299\n",
      "Loss after epoch=141: 2.482006\n",
      "Loss after epoch=142: 2.478716\n",
      "Loss after epoch=143: 2.475427\n",
      "Loss after epoch=144: 2.472139\n",
      "Loss after epoch=145: 2.468853\n",
      "Loss after epoch=146: 2.465568\n",
      "Loss after epoch=147: 2.462285\n",
      "Loss after epoch=148: 2.459003\n",
      "Loss after epoch=149: 2.455723\n",
      "Loss after epoch=150: 2.452445\n",
      "Loss after epoch=151: 2.449168\n",
      "Loss after epoch=152: 2.445893\n",
      "Loss after epoch=153: 2.442619\n",
      "Loss after epoch=154: 2.439347\n",
      "Loss after epoch=155: 2.436076\n",
      "Loss after epoch=156: 2.432807\n",
      "Loss after epoch=157: 2.429540\n",
      "Loss after epoch=158: 2.426274\n",
      "Loss after epoch=159: 2.423010\n",
      "Loss after epoch=160: 2.419747\n",
      "Loss after epoch=161: 2.416486\n",
      "Loss after epoch=162: 2.413227\n",
      "Loss after epoch=163: 2.409970\n",
      "Loss after epoch=164: 2.406714\n",
      "Loss after epoch=165: 2.403459\n",
      "Loss after epoch=166: 2.400207\n",
      "Loss after epoch=167: 2.396956\n",
      "Loss after epoch=168: 2.393707\n",
      "Loss after epoch=169: 2.390459\n",
      "Loss after epoch=170: 2.387214\n",
      "Loss after epoch=171: 2.383970\n",
      "Loss after epoch=172: 2.380728\n",
      "Loss after epoch=173: 2.377487\n",
      "Loss after epoch=174: 2.374248\n",
      "Loss after epoch=175: 2.371011\n",
      "Loss after epoch=176: 2.367776\n",
      "Loss after epoch=177: 2.364543\n",
      "Loss after epoch=178: 2.361311\n",
      "Loss after epoch=179: 2.358081\n",
      "Loss after epoch=180: 2.354853\n",
      "Loss after epoch=181: 2.351627\n",
      "Loss after epoch=182: 2.348402\n",
      "Loss after epoch=183: 2.345180\n",
      "Loss after epoch=184: 2.341959\n",
      "Loss after epoch=185: 2.338740\n",
      "Loss after epoch=186: 2.335523\n",
      "Loss after epoch=187: 2.332308\n",
      "Loss after epoch=188: 2.329094\n",
      "Loss after epoch=189: 2.325883\n",
      "Loss after epoch=190: 2.322674\n",
      "Loss after epoch=191: 2.319466\n",
      "Loss after epoch=192: 2.316260\n",
      "Loss after epoch=193: 2.313056\n",
      "Loss after epoch=194: 2.309855\n",
      "Loss after epoch=195: 2.306655\n",
      "Loss after epoch=196: 2.303457\n",
      "Loss after epoch=197: 2.300261\n",
      "Loss after epoch=198: 2.297067\n",
      "Loss after epoch=199: 2.293874\n"
     ]
    }
   ],
   "source": [
    " Wx,Wh,Wy,losses = trainRNN(df,Wx,Wh,Wy,h0,0.001,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xF = vectorize(df['Message'][1])\n",
    "# for t in range(xF.shape[1]):\n",
    "#     print(xF[:,t]) # Coloumn\n",
    "#     print(\"\\n\")\n",
    "#     print(torch.from_numpy(xF[:,np.newaxis]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = df_small['Message'].iloc[2]\n",
    "y = df_small['Mode'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Or thank you'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorize(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = fullForwardRNN(X,Wx,Wh,Wy,h0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9778]], dtype=torch.float64, grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
